Namespace(data='../dataset/VeRi/image_train/', trainlist='./list/veri_train_list.txt', dataset='veri', workers=4, batch_size=64, start_epoch=0, backbone='resnet50', weights='', scale_size=256, num_classes=576, write_out=True, crop_size=224, val_step=3, epochs=10, save_dir='./models/resnet50/', num_gpu=4)
====> Creating dataloader...
0.8
lr is  5e-05
  batch 1 loss: 0.07122066974639893
  batch 101 loss: 7.005304627418518
  batch 201 loss: 6.633555393218995
  batch 301 loss: 6.424524145126343
  batch 401 loss: 6.341570272445678
7555
LOSS train 6.341570272445678 valid 6.430723667144775
lr is  0.0001
  batch 1 loss: 0.06377669811248779
  batch 101 loss: 6.2460458374023435
  batch 201 loss: 6.150648655891419
  batch 301 loss: 5.990172929763794
  batch 401 loss: 5.8567868518829345
7555
LOSS train 5.8567868518829345 valid 5.769225120544434
lr is  0.00015000000000000001
  batch 1 loss: 0.05831319808959961
  batch 101 loss: 5.560999383926392
  batch 201 loss: 5.4795544147491455
  batch 301 loss: 5.324533724784851
  batch 401 loss: 5.205735974311828
7555
LOSS train 5.205735974311828 valid 5.125653266906738
lr is  0.0002
  batch 1 loss: 0.05151163101196289
  batch 101 loss: 5.055504856109619
  batch 201 loss: 4.984741764068604
  batch 301 loss: 4.881268701553345
  batch 401 loss: 4.798740305900574
7555
LOSS train 4.798740305900574 valid 4.840778827667236
lr is  0.00025
  batch 1 loss: 0.046071410179138184
  batch 101 loss: 4.657514629364013
  batch 201 loss: 4.593842258453369
  batch 301 loss: 4.5521614408493045
  batch 401 loss: 4.4376248621940615
7555
LOSS train 4.4376248621940615 valid 4.416502475738525
lr is  0.00030000000000000003
  batch 1 loss: 0.041784844398498534
  batch 101 loss: 4.345393440723419
  batch 201 loss: 4.278921713829041
  batch 301 loss: 4.213962295055389
  batch 401 loss: 4.151743953227997
7555
LOSS train 4.151743953227997 valid 4.051958084106445
lr is  0.00035
  batch 1 loss: 0.037629358768463135
  batch 101 loss: 4.009045054912567
  batch 201 loss: 3.965394320487976
  batch 301 loss: 3.8857515692710876
  batch 401 loss: 3.846026225090027
7555
LOSS train 3.846026225090027 valid 3.8767786026000977
lr is  0.0004
  batch 1 loss: 0.03802583456039429
  batch 101 loss: 3.7304192757606507
  batch 201 loss: 3.69385422706604
  batch 301 loss: 3.583340563774109
  batch 401 loss: 3.550213062763214
7555
LOSS train 3.550213062763214 valid 3.587907552719116
lr is  0.00045000000000000004
  batch 1 loss: 0.03539450407028198
  batch 101 loss: 3.4853438186645507
  batch 201 loss: 3.3746460461616516
  batch 301 loss: 3.2927140855789183
  batch 401 loss: 3.272820358276367
7555
LOSS train 3.272820358276367 valid 3.613960027694702
lr is  0.0005
  batch 1 loss: 0.03431421041488648
  batch 101 loss: 3.1941019105911255
  batch 201 loss: 3.0662063002586364
  batch 301 loss: 3.0579092359542845
  batch 401 loss: 2.9607073736190794
7555
LOSS train 2.9607073736190794 valid 3.1547129154205322
lr is  0.001
  batch 1 loss: 0.032884774208068845
  batch 101 loss: 3.371277165412903
  batch 201 loss: 3.3345033717155457
  batch 301 loss: 3.25832537651062
  batch 401 loss: 3.160986769199371
7555
LOSS train 3.160986769199371 valid 3.7842938899993896
