Namespace(data='../dataset/VeRi/image_train/', trainlist='./list/veri_train_list.txt', dataset='veri', workers=4, batch_size=64, start_epoch=0, backbone='resnet50', weights='', scale_size=256, num_classes=576, write_out=True, crop_size=224, val_step=10, epochs=50, save_dir='./models/resnet50/', num_gpu=4)
====> Creating dataloader...
0.8
lr is  5e-05
  batch 1 loss: 0.07531672000885009
  batch 101 loss: 6.987307620048523
  batch 201 loss: 6.6535452938079835
  batch 301 loss: 6.482378253936767
  batch 401 loss: 6.373954329490662
7555
LOSS train 6.373954329490662 valid 6.291660308837891
lr is  0.0001
  batch 1 loss: 0.06352200508117675
  batch 101 loss: 6.249861969947815
  batch 201 loss: 6.140226111412049
  batch 301 loss: 6.020265421867371
  batch 401 loss: 5.8637955951690675
7555
LOSS train 5.8637955951690675 valid 5.678542137145996
lr is  0.00015000000000000001
  batch 1 loss: 0.05383801937103271
  batch 101 loss: 5.590978517532348
  batch 201 loss: 5.42338809967041
  batch 301 loss: 5.322331490516663
  batch 401 loss: 5.22362479686737
7555
LOSS train 5.22362479686737 valid 5.117382526397705
lr is  0.0002
  batch 1 loss: 0.050618896484375
  batch 101 loss: 5.018024945259095
  batch 201 loss: 4.981349267959595
  batch 301 loss: 4.8555341768264775
  batch 401 loss: 4.788518290519715
7555
LOSS train 4.788518290519715 valid 4.857766151428223
lr is  0.00025
  batch 1 loss: 0.04736246109008789
  batch 101 loss: 4.665946383476257
  batch 201 loss: 4.587088794708252
  batch 301 loss: 4.505858039855957
  batch 401 loss: 4.424910469055176
7555
LOSS train 4.424910469055176 valid 4.491270065307617
lr is  0.00030000000000000003
  batch 1 loss: 0.04292057514190674
  batch 101 loss: 4.344679243564606
  batch 201 loss: 4.223220772743225
  batch 301 loss: 4.167492368221283
  batch 401 loss: 4.113641204833985
7555
LOSS train 4.113641204833985 valid 12.94755744934082
lr is  0.00035
  batch 1 loss: 0.03837952613830566
  batch 101 loss: 4.0200674343109135
  batch 201 loss: 3.9478837990760804
  batch 301 loss: 3.8519880270957945
  batch 401 loss: 3.7931546688079836
7555
LOSS train 3.7931546688079836 valid 4.060396671295166
lr is  0.0004
  batch 1 loss: 0.03874032974243164
  batch 101 loss: 3.7344199895858763
  batch 201 loss: 3.6182862019538877
  batch 301 loss: 3.6163888669013975
  batch 401 loss: 3.5567731189727785
7555
LOSS train 3.5567731189727785 valid 3.5788214206695557
lr is  0.00045000000000000004
  batch 1 loss: 0.03504637718200684
  batch 101 loss: 3.435366382598877
  batch 201 loss: 3.3454947805404665
  batch 301 loss: 3.344159893989563
  batch 401 loss: 3.2329149508476256
7555
LOSS train 3.2329149508476256 valid 3.870216131210327
lr is  0.0005
  batch 1 loss: 0.028988401889801025
  batch 101 loss: 3.152332234382629
  batch 201 loss: 3.1083817434310914
  batch 301 loss: 3.0480962347984315
  batch 401 loss: 3.008937678337097
7555
LOSS train 3.008937678337097 valid 3.3312056064605713
lr is  0.001
  batch 1 loss: 0.02559248924255371
  batch 101 loss: 3.3862925243377684
  batch 201 loss: 3.31807240486145
  batch 301 loss: 3.2444122362136842
  batch 401 loss: 3.076662743091583
7555
LOSS train 3.076662743091583 valid 3.6213529109954834
lr is  0.001
  batch 1 loss: 0.027459006309509277
  batch 101 loss: 2.933968434333801
  batch 201 loss: 2.850880620479584
  batch 301 loss: 2.8106697845458983
  batch 401 loss: 2.739421756267548
7555
LOSS train 2.739421756267548 valid 2.8210155963897705
lr is  0.001
  batch 1 loss: 0.02489995241165161
  batch 101 loss: 2.603966326713562
  batch 201 loss: 2.5724999070167542
  batch 301 loss: 2.5394082927703856
  batch 401 loss: 2.4249842095375063
7555
LOSS train 2.4249842095375063 valid 2.5591635704040527
lr is  0.001
  batch 1 loss: 0.021080799102783203
  batch 101 loss: 2.334350678920746
  batch 201 loss: 2.241285215616226
  batch 301 loss: 2.2335391628742216
  batch 401 loss: 2.152639729976654
7555
LOSS train 2.152639729976654 valid 2.4226226806640625
lr is  0.001
  batch 1 loss: 0.019608407020568847
  batch 101 loss: 2.049364483356476
  batch 201 loss: 2.0356067848205566
  batch 301 loss: 2.0046031641960145
  batch 401 loss: 1.9505193090438844
7555
LOSS train 1.9505193090438844 valid 2.218440055847168
lr is  0.001
  batch 1 loss: 0.016024558544158934
  batch 101 loss: 1.8287899816036224
  batch 201 loss: 1.8113983488082885
  batch 301 loss: 1.7599276292324066
  batch 401 loss: 1.7948681843280792
7555
LOSS train 1.7948681843280792 valid 2.223196506500244
lr is  0.001
  batch 1 loss: 0.02078853368759155
  batch 101 loss: 1.6457841074466706
  batch 201 loss: 1.634995460510254
  batch 301 loss: 1.627354509830475
  batch 401 loss: 1.5652835965156555
7555
LOSS train 1.5652835965156555 valid 2.016432285308838
lr is  0.001
  batch 1 loss: 0.016202815771102906
  batch 101 loss: 1.4591356563568114
  batch 201 loss: 1.50408608853817
  batch 301 loss: 1.4684658098220824
  batch 401 loss: 1.3740258699655532
7555
LOSS train 1.3740258699655532 valid 1.6605266332626343
lr is  0.001
  batch 1 loss: 0.014261540174484253
  batch 101 loss: 1.3847149038314819
  batch 201 loss: 1.2967467874288559
  batch 301 loss: 1.3084087097644805
  batch 401 loss: 1.3157048738002777
7555
LOSS train 1.3157048738002777 valid 1.9210968017578125
lr is  0.001
  batch 1 loss: 0.014150965213775634
  batch 101 loss: 1.2388222181797028
  batch 201 loss: 1.1880988109111785
  batch 301 loss: 1.1575736367702485
  batch 401 loss: 1.1942964202165605
7555
LOSS train 1.1942964202165605 valid 1.3447506427764893
lr is  0.001
  batch 1 loss: 0.010105644464492797
  batch 101 loss: 1.0960941344499588
  batch 201 loss: 1.0574451816082
  batch 301 loss: 1.1076525962352752
  batch 401 loss: 1.0782279109954833
7555
LOSS train 1.0782279109954833 valid 1.4629268646240234
lr is  0.001
  batch 1 loss: 0.005922531485557556
  batch 101 loss: 1.0115835356712342
  batch 201 loss: 1.022820109128952
  batch 301 loss: 1.0029506331682205
  batch 401 loss: 1.008630775809288
7555
LOSS train 1.008630775809288 valid 1.1905150413513184
lr is  0.001
  batch 1 loss: 0.010467596054077148
  batch 101 loss: 0.9435870462656021
  batch 201 loss: 0.9232624614238739
  batch 301 loss: 0.8877271401882172
  batch 401 loss: 0.9211915630102158
7555
LOSS train 0.9211915630102158 valid 1.1932145357131958
lr is  0.001
  batch 1 loss: 0.008328275680541992
  batch 101 loss: 0.8789931631088257
  batch 201 loss: 0.8126628616452217
  batch 301 loss: 0.8441641110181809
  batch 401 loss: 0.8586359182000161
7555
LOSS train 0.8586359182000161 valid 1.3273158073425293
lr is  0.001
  batch 1 loss: 0.008843148350715637
  batch 101 loss: 0.8743149983882904
  batch 201 loss: 0.7988532400131225
  batch 301 loss: 0.7796863213181495
  batch 401 loss: 0.7688677349686622
7555
LOSS train 0.7688677349686622 valid 0.9401246905326843
lr is  0.001
  batch 1 loss: 0.006293079257011414
  batch 101 loss: 0.7157293969392776
  batch 201 loss: 0.7205369621515274
  batch 301 loss: 0.7256627231836319
  batch 401 loss: 0.7205845284461975
7555
LOSS train 0.7205845284461975 valid 0.9169604778289795
lr is  0.001
  batch 1 loss: 0.004801452755928039
  batch 101 loss: 0.6426367726922035
  batch 201 loss: 0.6540294972062111
  batch 301 loss: 0.683822953402996
  batch 401 loss: 0.656205532848835
7555
LOSS train 0.656205532848835 valid 0.8213292956352234
lr is  0.001
  batch 1 loss: 0.006424944996833801
  batch 101 loss: 0.6558164760470391
  batch 201 loss: 0.6036472615599632
  batch 301 loss: 0.6429092907905578
  batch 401 loss: 0.6331443640589715
7555
LOSS train 0.6331443640589715 valid 0.9128977656364441
lr is  0.001
  batch 1 loss: 0.007378857731819153
  batch 101 loss: 0.6088115686178207
  batch 201 loss: 0.5819777506589889
  batch 301 loss: 0.5759132304787635
  batch 401 loss: 0.5905652704834938
7555
LOSS train 0.5905652704834938 valid 0.752772867679596
lr is  0.001
  batch 1 loss: 0.006667623519897461
  batch 101 loss: 0.542682199627161
  batch 201 loss: 0.5543644152581692
  batch 301 loss: 0.5399908328056335
  batch 401 loss: 0.5260234040021896
7555
LOSS train 0.5260234040021896 valid 0.9331362247467041
lr is  0.001
  batch 1 loss: 0.0049709507822990415
  batch 101 loss: 0.5361907523870468
  batch 201 loss: 0.5343266393244267
  batch 301 loss: 0.5071419273316861
  batch 401 loss: 0.5319894245266914
7555
LOSS train 0.5319894245266914 valid 0.7635288238525391
lr is  0.001
  batch 1 loss: 0.003157981336116791
  batch 101 loss: 0.4894657884538174
  batch 201 loss: 0.4954995408654213
  batch 301 loss: 0.4992255806922913
  batch 401 loss: 0.5029258981347084
7555
LOSS train 0.5029258981347084 valid 0.824838399887085
lr is  0.001
  batch 1 loss: 0.0067204517126083375
  batch 101 loss: 0.45267015606164934
  batch 201 loss: 0.43721470430493353
  batch 301 loss: 0.45834801711142065
  batch 401 loss: 0.4595660389959812
7555
LOSS train 0.4595660389959812 valid 0.6605613231658936
lr is  0.001
  batch 1 loss: 0.0034614422917366027
  batch 101 loss: 0.4431108020246029
  batch 201 loss: 0.4231555937230587
  batch 301 loss: 0.4379113295674324
  batch 401 loss: 0.441338699311018
7555
LOSS train 0.441338699311018 valid 0.9911597371101379
lr is  0.001
  batch 1 loss: 0.0024600949883460997
  batch 101 loss: 0.40558725625276565
  batch 201 loss: 0.4332450687885284
  batch 301 loss: 0.4195642238855362
  batch 401 loss: 0.3936802028119564
7555
LOSS train 0.3936802028119564 valid 0.7489338517189026
lr is  0.001
  batch 1 loss: 0.0019136416912078858
  batch 101 loss: 0.38722018361091615
  batch 201 loss: 0.41128138661384583
  batch 301 loss: 0.37065444454550744
  batch 401 loss: 0.403272046148777
7555
LOSS train 0.403272046148777 valid 0.7964182496070862
lr is  0.001
  batch 1 loss: 0.0034961307048797605
  batch 101 loss: 0.3853134949505329
  batch 201 loss: 0.35244108974933624
  batch 301 loss: 0.4004385989904404
  batch 401 loss: 0.36852454259991646
7555
LOSS train 0.36852454259991646 valid 0.5937937498092651
lr is  0.001
  batch 1 loss: 0.004809464514255524
  batch 101 loss: 0.3654285179078579
  batch 201 loss: 0.35462465025484563
  batch 301 loss: 0.33710460364818573
  batch 401 loss: 0.36018822774291037
7555
LOSS train 0.36018822774291037 valid 0.5773507356643677
lr is  0.001
  batch 1 loss: 0.0026071885228157042
  batch 101 loss: 0.33118204563856124
  batch 201 loss: 0.32833512015640737
  batch 301 loss: 0.3414238342642784
  batch 401 loss: 0.341875791400671
7555
LOSS train 0.341875791400671 valid 0.5824140310287476
lr is  0.001
  batch 1 loss: 0.0020018337666988374
  batch 101 loss: 0.3260004537552595
  batch 201 loss: 0.32424251429736617
  batch 301 loss: 0.3402585273981094
  batch 401 loss: 0.33604021042585375
7555
LOSS train 0.33604021042585375 valid 0.7022144198417664
lr is  0.0001
  batch 1 loss: 0.0027802544832229614
  batch 101 loss: 0.26527431823313236
  batch 201 loss: 0.18038199573755265
  batch 301 loss: 0.16028973150998355
  batch 401 loss: 0.14997440876439214
7555
LOSS train 0.14997440876439214 valid 0.29824623465538025
lr is  0.0001
  batch 1 loss: 0.0017775858938694
  batch 101 loss: 0.14333676677197218
  batch 201 loss: 0.13107589408755302
  batch 301 loss: 0.12871131625957788
  batch 401 loss: 0.11781072109937668
7555
LOSS train 0.11781072109937668 valid 0.2829321324825287
lr is  0.0001
  batch 1 loss: 0.0008794230967760086
  batch 101 loss: 0.11623199392110109
  batch 201 loss: 0.10867949006147683
  batch 301 loss: 0.11889054851606488
  batch 401 loss: 0.11651346046477556
7555
LOSS train 0.11651346046477556 valid 0.25679486989974976
lr is  0.0001
  batch 1 loss: 0.0005537514016032219
  batch 101 loss: 0.10298048766329884
  batch 201 loss: 0.09989877806976438
  batch 301 loss: 0.09523663442581892
  batch 401 loss: 0.1125651747174561
7555
LOSS train 0.1125651747174561 valid 0.2493758201599121
lr is  0.0001
  batch 1 loss: 0.000544281005859375
  batch 101 loss: 0.10493624947965145
  batch 201 loss: 0.084912573043257
  batch 301 loss: 0.09420502449385822
  batch 401 loss: 0.09887037705630064
7555
LOSS train 0.09887037705630064 valid 0.23084992170333862
lr is  0.0001
  batch 1 loss: 0.00043695695698261263
  batch 101 loss: 0.08701503040269017
  batch 201 loss: 0.08772186813876033
  batch 301 loss: 0.08774864606559277
  batch 401 loss: 0.09019116282463074
7555
LOSS train 0.09019116282463074 valid 0.24752312898635864
lr is  0.0001
  batch 1 loss: 0.00016545964404940605
  batch 101 loss: 0.08239824591204524
  batch 201 loss: 0.07690146605484188
  batch 301 loss: 0.07994602256454528
  batch 401 loss: 0.0778451261203736
7555
LOSS train 0.0778451261203736 valid 0.23614010214805603
lr is  0.0001
  batch 1 loss: 0.0006342548131942749
  batch 101 loss: 0.08253393424674868
  batch 201 loss: 0.08413492849096656
  batch 301 loss: 0.07985848027281463
  batch 401 loss: 0.08242257140111178
7555
LOSS train 0.08242257140111178 valid 0.20330671966075897
lr is  0.0001
  batch 1 loss: 0.0006597250699996948
  batch 101 loss: 0.07060148386284709
  batch 201 loss: 0.08120736835524439
  batch 301 loss: 0.07379887552931905
  batch 401 loss: 0.08138907209970057
7555
LOSS train 0.08138907209970057 valid 0.2120281457901001
lr is  0.0001
  batch 1 loss: 0.0011920766532421113
  batch 101 loss: 0.07394498123787344
  batch 201 loss: 0.06540903500281274
  batch 301 loss: 0.075274638235569
  batch 401 loss: 0.07190947091206908
7555
LOSS train 0.07190947091206908 valid 0.2140708565711975
lr is  0.0001
  batch 1 loss: 0.0005651705339550972
  batch 101 loss: 0.07024029685650021
  batch 201 loss: 0.07510302993934602
  batch 301 loss: 0.06869683265220373
  batch 401 loss: 0.06308237695135176
7555
LOSS train 0.06308237695135176 valid 0.21461281180381775
